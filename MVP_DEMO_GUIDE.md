# SaaS X-Ray MVP Demo Guide
## Business Partner Meeting - January 2, 2025

---

## üéØ **Demo Overview**
**Duration**: 10 minutes (casual meeting)
**Objective**: Show how SaaS X-Ray discovers AI automations that pose GDPR and PII compliance risks
**Key Message**: "We find AI automations with access to sensitive data that your security team doesn't know exist"

**Important**: This is a discovery and risk assessment tool - we identify automations with risky permissions, not actual data flows.

---

## üöÄ **Demo Flow**

### **Opening Hook** (2 minutes)
*"Most companies today have AI automations running in their Google Workspace - ChatGPT integrations, automated data processors, third-party AI services. The problem is, your security team has no idea they exist. Let me show you what we typically find."*

### **1. Quick Discovery** (3 minutes)
**Screen**: Click "Discover" on Google Workspace connection
**Live Demo**: Shows discovery in progress, then results

**What We Show**:
```
‚úÖ 3 AI Automations Discovered
‚ö†Ô∏è 2 High-Risk (potential GDPR issues)
‚è±Ô∏è Discovery Time: 2.8 seconds
```

### **2. AI Risk Assessment** (4 minutes)
**Screen**: Automations Dashboard showing AI-related results

**High-Risk Example - "ChatGPT Data Processor"**:
- **What we detect**: Apps Script with OpenAI API access + Sheets permissions
- **Risk factors**: 
  - ‚úÖ Can access spreadsheet data (potential PII)
  - ‚úÖ Has OpenAI in URL whitelist
  - ‚úÖ Automated triggers (processes data without human oversight)
  - ‚úÖ No audit trail visible

**Talking Point**: *"We can't see what data it's actually sending, but this automation has everything it needs to send your spreadsheet data to ChatGPT. That's a GDPR risk your security team should know about."*

**Service Account Example - "AI-Integration-Bot"**:
- **What we detect**: Service account with Drive access + external API permissions
- **Risk factors**: Third-party integration, multiple API keys, recent activity

### **3. Business Reality Check** (1 minute)
**Key Message**: *"We're not tracking your actual data - that would require installing agents or proxies. What we ARE doing is finding automations that COULD be creating compliance risks, so your security team can investigate the ones that matter."*

---

## üíº **Honest Value Proposition**

### **What We Actually Do**:
1. **Discovery**: Find AI automations your security team doesn't know exist
2. **Risk Assessment**: Identify which have permissions that could violate GDPR
3. **Prioritization**: Focus investigation on highest-risk automations first
4. **Evidence**: Document what permissions each automation has

### **What We Don't Do** (Be Clear About This):
- ‚ùå Track actual data flows to AI services
- ‚ùå Monitor real-time data transmission
- ‚ùå Prove that violations have occurred
- ‚ùå Block or prevent data transfer

### **The Real Business Value**:
- **Discovery Speed**: Manual audit takes weeks ‚Üí We find automations in seconds
- **Risk Prioritization**: Focus on the 3-5 that actually matter, not 500 false positives  
- **Compliance Preparation**: Know what to investigate before the audit
- **Shadow AI Visibility**: IT teams are blind to these integrations

---

## üé¨ **Honest Demo Script**

### **Opening** 
*"Every company I talk to has the same problem - employees are connecting AI tools to their Google Workspace data, and security teams have no visibility into it. Let me show you what we typically find."*

### **During Discovery**
*"In 3 seconds, we're scanning for automations that have both data access AND external API permissions. This combination creates GDPR risk that most companies don't even know exists."*

### **Highlighting AI Risks**
*"Look at this automation - it has access to spreadsheets AND it's whitelisted to call the OpenAI API. We can't see what data it's sending, but it has everything it needs to send your customer data to ChatGPT. That's a compliance risk worth investigating."*

### **Being Honest About Limitations**
*"To be clear, we're not monitoring your actual data flows - that would require network agents or proxies. What we ARE doing is finding the automations that could be creating risks, so your security team knows where to look."*

### **Business Impact**
*"The value isn't in preventing breaches - it's in discovery. Most companies have 10-20 of these AI integrations they don't know about. We help you find them before your next compliance audit does."*

---

## üìä **Demo Data (Mock for MVP)**

### **AI-Focused Automations We Show**:

| Name | Type | Risk | What We Detect |
|------|------|------|----------------|
| ChatGPT Data Processor | Apps Script | HIGH (65) | OpenAI API + Sheets access + Auto triggers |
| Claude Document Analyzer | Apps Script | HIGH (60) | Anthropic API + Drive access + Form processing |
| AI-Integration Service Account | Service Account | MED (45) | Multiple APIs + Recent activity + Third-party pattern |

### **What Each Risk Score Means**:
- **HIGH (50+)**: Has data access + AI API endpoints + automated execution
- **MEDIUM (25-49)**: Has data access + external permissions but limited automation
- **LOW (<25)**: Limited permissions or internal-only automation

### **Detection Capabilities (Be Honest)**:
- **What we see**: OAuth permissions, API whitelists, automation triggers
- **What we infer**: Potential for data transmission to AI services  
- **What we can't see**: Actual data content, real-time flows, historical transfers
- **Processing Speed**: ~3 seconds for permission-based assessment

---

## üîß **Technical Setup (Pre-Demo Checklist)**

### **Backend Status**:
- ‚úÖ Server running on `http://localhost:3001`
- ‚úÖ Google Workspace connector active
- ‚úÖ Mock discovery data populated
- ‚úÖ Risk assessment algorithms functional

### **Frontend Status**:
- ‚úÖ Dashboard accessible at `http://localhost:3003`
- ‚úÖ Authentication working (admin@example.com / SecurePass123!)
- ‚úÖ Connections page shows both platforms
- ‚úÖ Discovery results displaying correctly

### **Demo Environment URLs**:
- **Health Check**: `http://localhost:3001/api/health`
- **Connections API**: `http://localhost:3001/api/connections`
- **Discovery API**: `http://localhost:3001/api/connections/conn-2/discover`
- **Frontend Dashboard**: `http://localhost:3003`

---

## üéØ **Key Differentiators to Emphasize**

### **vs Manual Auditing**:
- **Speed**: 3 seconds vs weeks of manual work
- **Completeness**: Automated discovery vs human oversight gaps
- **Consistency**: Same analysis every time vs variable human judgment

### **vs General Security Tools**:
- **Automation-Focused**: Built specifically for bot/automation detection
- **Cross-Platform**: Single view across all SaaS tools
- **Risk Context**: Not just detection, but business risk assessment

### **vs Competitors**:
- **Real-Time**: Continuous monitoring vs point-in-time scans
- **Intelligence**: AI-powered risk scoring vs simple rule matching
- **Actionable**: Specific remediation guidance vs generic alerts

---

## üí¨ **Honest Q&A Section**

**Q: "Can you actually see what data is being sent to AI services?"**
A: "No, we can't see the actual data content. What we CAN see is that an automation has both data access permissions AND AI API endpoints. That combination creates risk that's worth investigating."

**Q: "How do you detect AI integrations?"**
A: "We scan for automations that have external URL permissions and look for AI service domains in their whitelists - like api.openai.com, api.anthropic.com, etc. Plus we analyze naming patterns and service accounts."

**Q: "What about false positives?"**
A: "We focus on permission combinations that create real risk. If something has spreadsheet access AND OpenAI API access, that's worth knowing about regardless of whether it's actively being used maliciously."

**Q: "How is this different from just reviewing OAuth permissions manually?"**
A: "Manual review takes weeks and misses context. We automatically find automations, analyze their permission combinations, and prioritize by risk. We turn a 40-hour manual audit into a 3-second automated scan."

**Q: "What can't your system detect?"**
A: "We can't see actual data flows, can't monitor real-time transmissions, and can't prove violations have occurred. We're a discovery and risk assessment tool, not a data loss prevention system."

**Q: "Is this just for Google Workspace?"**
A: "This demo shows Google, but the same permission-based approach works for Slack, Microsoft 365, Salesforce - anywhere OAuth is used to grant automations access to data."

---

## üéâ **Honest Closing**

### **Realistic Close**:
*"In 10 minutes, we've shown you how to discover AI automations that security teams typically miss. The value isn't in stopping breaches - it's in knowing what's out there so you can make informed decisions about risk."*

### **Casual Call to Action**:
*"This is still early-stage, but if this kind of visibility into AI integrations would be valuable for your customers, let's talk about how we might work together. I'd be curious to hear what other automation risks you're seeing in the market."*

### **Next Steps**:
1. **Follow-up conversation** about their customer needs
2. **Technical demo** with their team if there's interest
3. **Pilot discussion** if this fits their portfolio

---

## üìã **Demo Day Checklist**

### **30 Minutes Before**:
- [ ] Navigate to `/backend` and start simple server
- [ ] Open `http://localhost:3003` and test login (admin@example.com / SecurePass123!)
- [ ] Test Google discovery endpoint once
- [ ] Have this guide open for talking points

### **During Demo** (Keep it casual):
- [ ] Be honest about capabilities and limitations
- [ ] Focus on the discovery value, not prevention claims
- [ ] Ask about their customer's automation challenges
- [ ] Listen more than you present

### **After Demo**:
- [ ] Follow up within a few days (not 24 hours - too eager)
- [ ] Send summary of what you showed
- [ ] Ask about their thoughts on market fit

---

## üöÄ **Realistic Success Metrics**

**Good Meeting Indicators**:
- They ask about technical details or limitations
- They share similar challenges they've seen with customers
- They want to show this to their team
- They discuss how it might fit with their existing tools
- They ask thoughtful questions about the market

**Best Case Outcome**:
Interest in exploring partnership opportunities with follow-up meetings to discuss how this could complement their existing security offerings.

**Remember**:
- This is an early-stage MVP
- Be honest about current capabilities  
- Focus on discovery value over prevention claims
- Listen for market validation and partnership opportunities

**Good luck! üöÄ**